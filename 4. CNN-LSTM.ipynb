{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 19:25:15.229056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-03 19:25:16.741430: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 19:25:16.745730: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-10-03 19:25:16.771230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2023-10-03 19:25:16.771263: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-03 19:25:16.775419: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-10-03 19:25:16.775474: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-10-03 19:25:16.776879: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-10-03 19:25:16.777180: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-10-03 19:25:16.778418: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-10-03 19:25:16.779445: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-10-03 19:25:16.779598: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-10-03 19:25:16.780607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-10-03 19:25:16.780652: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-10-03 19:25:17.597533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-10-03 19:25:17.597581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-10-03 19:25:17.597591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-10-03 19:25:17.599241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 11419 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5423443410737273241\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11974344704\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12249524192495599302\n",
      "physical_device_desc: \"device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, ReLU, LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from focal_loss import BinaryFocalLoss\n",
    "\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183311, 5, 24, 16)\n",
      "(183311, 2)\n",
      "(86000, 5, 24, 16)\n",
      "(86000, 2)\n",
      "training data 중 abnormal :  97800\n"
     ]
    }
   ],
   "source": [
    "feature = ['flux',\n",
    "           'zero_month',\n",
    "           'zero_week',\n",
    "           'continuous_zero',\n",
    "           'diff_week_day',\n",
    "           'diff_month',\n",
    "           'std_week',\n",
    "           'diff_std',\n",
    "           'rec_day',\n",
    "           'rec_week',\n",
    "           'rec_2week',\n",
    "           'rec_month',\n",
    "           'rec_day2',\n",
    "           'rec_week2',\n",
    "           'rec_2week2',\n",
    "           'rec_month2', ]\n",
    "\n",
    "total_df = pd.read_csv(\"../final_data.csv\")\n",
    "total_data = total_df.dropna().loc[:, ['label'] + feature].to_numpy()\n",
    "\n",
    "window_n = 5\n",
    "stride = 12\n",
    "window_size = 24\n",
    "\n",
    "normal_data = []\n",
    "abnormal_data = []\n",
    "where_abnormal = np.argwhere(total_data[:,0]==1)\n",
    "\n",
    "# normal_data 추출 과정\n",
    "for i in range(total_data.shape[0] - (window_size + (window_n - 1) * stride)):\n",
    "  # 무작위성 부여\n",
    "  if np.random.rand() > 0.30:\n",
    "    continue\n",
    "  \n",
    "  sliced = []\n",
    "  for w_n in range(window_n):\n",
    "    # sliced 에 window_n번 window_size 행만큼 자른 데이터 append\n",
    "    # sliced 에 5번 24x17 추가\n",
    "    sliced.append(total_data[(w_n * stride) + i : (w_n * stride) + i + window_size])\n",
    "  \n",
    "  sliced = np.array(sliced)\n",
    "\n",
    "  # 자른 데이터 label이 모두 정상이면 normal 추가\n",
    "  if np.all(sliced[:,:,0] == 0):\n",
    "    normal_data.append(sliced[:, :, 1:])\n",
    "\n",
    "normal_data = np.array(normal_data).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# abnormal_data 추출 과정\n",
    "for ab in where_abnormal:\n",
    "    # 이전 24 + 12*4 시간의 data를 보고 진단 == 72시간\n",
    "    # 그냥 ab 로 하면 list --> ab[0]\n",
    "    i = ab[0] + 1 - window_size - stride * (window_n - 1)\n",
    "    if (i < 0):\n",
    "        continue\n",
    "    \n",
    "    sliced = []\n",
    "    for w_n in range(window_n):\n",
    "        sliced.append(total_data[i + (w_n * stride) : i + (w_n * stride) + window_size, 1:])\n",
    "    \n",
    "    sliced = np.array(sliced)\n",
    "    abnormal_data.append(sliced)\n",
    "\n",
    "#abnormal_data : 고장 직전 72시간의 데이터를 포함\n",
    "abnormal_data = np.array(abnormal_data).astype(np.float32)\n",
    "\n",
    "# Index Shuffle\n",
    "random_idx = np.arange(normal_data.shape[0])\n",
    "np.random.shuffle(random_idx)\n",
    "normal_data = normal_data[random_idx]\n",
    "\n",
    "random_idx = np.arange(abnormal_data.shape[0])\n",
    "np.random.shuffle(random_idx)\n",
    "abnormal_data = abnormal_data[random_idx]\n",
    "\n",
    "\n",
    "cut = normal_data.shape[0]//10\n",
    "\n",
    "# Training Dataset\n",
    "training_x = normal_data[:cut]\n",
    "training_y = [[1, 0] for _ in range(cut)]\n",
    "\n",
    "# abnormal data oversampling 200 times\n",
    "duplicate_weight = 200\n",
    "for _ in range(duplicate_weight):\n",
    "  training_x = np.concatenate([training_x, abnormal_data[:abnormal_data.shape[0]//2]], axis = 0)\n",
    "\n",
    "\n",
    "training_y = training_y + [[0, 1] for _ in range(training_x.shape[0]-len(training_y))]\n",
    "training_y = np.array(training_y)\n",
    "\n",
    "\n",
    "# Test Dataset\n",
    "test_x = normal_data[cut:cut*2]\n",
    "test_y = [[1, 0] for _ in range(cut)]\n",
    "\n",
    "test_x = np.concatenate([test_x, abnormal_data[abnormal_data.shape[0]//2:]], axis = 0)\n",
    "test_y = test_y + [[0, 1] for _ in range(test_x.shape[0]-len(test_y))]\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "\n",
    "# Dataset Labeling\n",
    "# normal : [1,0]\n",
    "# abnormal : [0,1]\n",
    "\n",
    "print(training_x.shape)\n",
    "print(training_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "print(\"training data 중 abnormal : \", sum(training_y[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "645/645 [==============================] - 7s 7ms/step - loss: 0.3860 - accuracy: 0.8749 - val_loss: 0.3866 - val_accuracy: 0.7426\n",
      "Epoch 2/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.2814 - accuracy: 0.8888 - val_loss: 0.2767 - val_accuracy: 0.9225\n",
      "Epoch 3/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.2496 - accuracy: 0.9132 - val_loss: 0.2640 - val_accuracy: 0.9040\n",
      "Epoch 4/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.2142 - accuracy: 0.9328 - val_loss: 0.2321 - val_accuracy: 0.8938\n",
      "Epoch 5/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1887 - accuracy: 0.9448 - val_loss: 0.1766 - val_accuracy: 0.9594\n",
      "Epoch 6/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1644 - accuracy: 0.9534 - val_loss: 0.1667 - val_accuracy: 0.9614\n",
      "Epoch 7/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1540 - accuracy: 0.9551 - val_loss: 0.1742 - val_accuracy: 0.9492\n",
      "Epoch 8/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1433 - accuracy: 0.9586 - val_loss: 0.1701 - val_accuracy: 0.9573\n",
      "Epoch 9/10\n",
      "645/645 [==============================] - 4s 7ms/step - loss: 0.1317 - accuracy: 0.9607 - val_loss: 0.1384 - val_accuracy: 0.9593\n",
      "Epoch 10/10\n",
      "645/645 [==============================] - 4s 6ms/step - loss: 0.1263 - accuracy: 0.9626 - val_loss: 0.1381 - val_accuracy: 0.9654\n",
      "424 85432 79 65\n",
      "precision:  0.8429423459244533\n",
      "recall:  0.8670756646216768\n",
      "F-measure: 0.8548386596873809\n",
      "MCC: 0.854082861860939\n",
      "train time :  44.06989645957947\n"
     ]
    }
   ],
   "source": [
    "l2param=0.001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(\n",
    "  Conv1D(32, 4, padding = \"valid\",\n",
    "         kernel_regularizer=tf.keras.regularizers.l2(l2param))\n",
    "  ))\n",
    "model.add(TimeDistributed(ReLU()))\n",
    "model.add(TimeDistributed(MaxPooling1D(2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(units=256,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2param)\n",
    "              ))\n",
    "model.add(Dense(2, activation='sigmoid',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2param)))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(training_x, training_y, epochs=10, batch_size=256, validation_split=0.1)\n",
    "end = time.time()\n",
    "\n",
    "pred = model.predict(test_x, batch_size=256)[:,1]\n",
    "test_ground_truth = test_y[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(test_ground_truth, pred)\n",
    "\n",
    "# test_y\n",
    "# normal : [1,0]\n",
    "# abnormal : [0,1]\n",
    "\n",
    "for i in range(len(fpr)):\n",
    "        if fpr[i] > 0.001: #0.1%\n",
    "            # fpr 이 thresholds 값 이상이 될 때 그 index 를 찾음\n",
    "            if (i > 0): i -= 1\n",
    "            break\n",
    "\n",
    "predicted = pred >= thresholds[i]\n",
    "TP = int(sum(np.logical_and(test_ground_truth==1,  predicted==1)))\n",
    "TN = int(sum(np.logical_and(test_ground_truth==0,  predicted==0)))\n",
    "FP = int(sum(np.logical_and(test_ground_truth==0,  predicted==1)))\n",
    "FN = int(sum(np.logical_and(test_ground_truth==1,  predicted==0)))\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "print(TP, TN, FP, FN)\n",
    "\n",
    "print(\"precision: \", Precision)\n",
    "print(\"recall: \", Recall)\n",
    "print(\"F-measure:\", (2*Precision*Recall)/(Precision+Recall+1e-7))\n",
    "print(\"MCC:\", (TP*TN-FP*FN)/(np.sqrt(float((TP+FN)*(TP+FP)*(TN+FP)*(TN+FN)))+1e-7))\n",
    "print(\"train time : \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 0.1\n",
      "407 85348 82 82\n",
      "precision:  0.8323108384458078\n",
      "recall:  0.8323108384458078\n",
      "F-measure: 0.8323107884458106\n",
      "MCC: 0.8313509882760762\n",
      "====================\n",
      "gamma = 0.2\n",
      "425 85347 83 64\n",
      "precision:  0.8366141732283464\n",
      "recall:  0.869120654396728\n",
      "F-measure: 0.8525576230372189\n",
      "MCC: 0.851854048959945\n",
      "====================\n",
      "gamma = 0.30000000000000004\n",
      "414 85357 73 75\n",
      "precision:  0.8501026694045175\n",
      "recall:  0.8466257668711656\n",
      "F-measure: 0.8483606057379178\n",
      "MCC: 0.8474962630502637\n",
      "====================\n",
      "gamma = 0.4\n",
      "426 85360 70 63\n",
      "precision:  0.8588709677419355\n",
      "recall:  0.8711656441717791\n",
      "F-measure: 0.8649745692918682\n",
      "MCC: 0.8642182876166802\n",
      "====================\n",
      "gamma = 0.5\n",
      "424 85345 85 65\n",
      "precision:  0.8330058939096268\n",
      "recall:  0.8670756646216768\n",
      "F-measure: 0.8496993488176784\n",
      "MCC: 0.848994233366785\n",
      "====================\n",
      "gamma = 0.6\n",
      "406 85347 83 83\n",
      "precision:  0.8302658486707567\n",
      "recall:  0.8302658486707567\n",
      "F-measure: 0.8302657986707597\n",
      "MCC: 0.8292942930111503\n",
      "====================\n",
      "gamma = 0.7000000000000001\n",
      "422 85349 81 67\n",
      "precision:  0.8389662027833003\n",
      "recall:  0.8629856850715747\n",
      "F-measure: 0.8508064016228649\n",
      "MCC: 0.8500259894879905\n",
      "====================\n",
      "gamma = 0.8\n",
      "427 85353 77 62\n",
      "precision:  0.8472222222222222\n",
      "recall:  0.8732106339468303\n",
      "F-measure: 0.8600200909983204\n",
      "MCC: 0.859305912852193\n",
      "====================\n",
      "gamma = 0.9\n",
      "389 85367 63 100\n",
      "precision:  0.8606194690265486\n",
      "recall:  0.7955010224948875\n",
      "F-measure: 0.8267799713312907\n",
      "MCC: 0.8264738957577775\n",
      "====================\n",
      "gamma = 1.0\n",
      "414 85362 68 75\n",
      "precision:  0.8589211618257261\n",
      "recall:  0.8466257668711656\n",
      "F-measure: 0.852729095213724\n",
      "MCC: 0.8519146705652553\n",
      "====================\n",
      "gamma = 1.1\n",
      "416 85346 84 73\n",
      "precision:  0.832\n",
      "recall:  0.8507157464212679\n",
      "F-measure: 0.841253741714985\n",
      "MCC: 0.8403875517797469\n",
      "====================\n",
      "gamma = 1.2000000000000002\n",
      "427 85355 75 62\n",
      "precision:  0.850597609561753\n",
      "recall:  0.8732106339468303\n",
      "F-measure: 0.8617557522285869\n",
      "MCC: 0.8610290034744431\n",
      "====================\n",
      "gamma = 1.3000000000000003\n",
      "427 85354 76 62\n",
      "precision:  0.8489065606361829\n",
      "recall:  0.8732106339468303\n",
      "F-measure: 0.8608870467841552\n",
      "MCC: 0.8601661768100499\n",
      "====================\n",
      "gamma = 1.4000000000000001\n",
      "401 85350 80 88\n",
      "precision:  0.8336798336798337\n",
      "recall:  0.820040899795501\n",
      "F-measure: 0.8268040737147442\n",
      "MCC: 0.8258493832527283\n",
      "====================\n",
      "gamma = 1.5000000000000002\n",
      "408 85345 85 81\n",
      "precision:  0.8275862068965517\n",
      "recall:  0.8343558282208589\n",
      "F-measure: 0.8309571801433987\n",
      "MCC: 0.8299926329474386\n",
      "====================\n",
      "gamma = 1.6\n",
      "407 85348 82 82\n",
      "precision:  0.8323108384458078\n",
      "recall:  0.8323108384458078\n",
      "F-measure: 0.8323107884458106\n",
      "MCC: 0.8313509882760762\n",
      "====================\n",
      "gamma = 1.7000000000000002\n",
      "401 85356 74 88\n",
      "precision:  0.8442105263157895\n",
      "recall:  0.820040899795501\n",
      "F-measure: 0.8319501574794284\n",
      "MCC: 0.8310909814373315\n",
      "====================\n",
      "gamma = 1.8000000000000003\n",
      "421 85347 83 68\n",
      "precision:  0.8353174603174603\n",
      "recall:  0.8609406952965235\n",
      "F-measure: 0.8479354988533053\n",
      "MCC: 0.8471496945520511\n",
      "====================\n",
      "gamma = 1.9000000000000001\n",
      "412 85347 83 77\n",
      "precision:  0.8323232323232324\n",
      "recall:  0.8425357873210634\n",
      "F-measure: 0.8373983239856019\n",
      "MCC: 0.8364776669251524\n",
      "====================\n",
      "gamma = 2.0\n",
      "379 85345 85 110\n",
      "precision:  0.8168103448275862\n",
      "recall:  0.7750511247443763\n",
      "F-measure: 0.7953829510837296\n",
      "MCC: 0.7945191572769297\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "l2param=0.001\n",
    "\n",
    "gamm = [0.5, 1, 1.5, 2.0]\n",
    "for gam in gamm :\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(\n",
    "      Conv1D(32, 4, padding = \"valid\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l2param))\n",
    "      ))\n",
    "    model.add(TimeDistributed(ReLU()))\n",
    "    model.add(TimeDistributed(MaxPooling1D(2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(LSTM(units=256,\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2param)\n",
    "                  ))\n",
    "    model.add(Dense(2, activation='sigmoid',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(l2param)))\n",
    "    model.compile(loss=BinaryFocalLoss(gamma=gam), optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "    model.fit(training_x, training_y, epochs=10, batch_size=256, verbose=0, validation_split=0.1)\n",
    "\n",
    "    print('gamma = {}'.format(gam))\n",
    "\n",
    "    pred = model.predict(test_x, batch_size=256)[:,1]\n",
    "    test_ground_truth = test_y[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_ground_truth, pred)\n",
    "\n",
    "    # test_y\n",
    "    # normal : [1,0]\n",
    "    # abnormal : [0,1]\n",
    "\n",
    "    for i in range(len(fpr)):\n",
    "            if fpr[i] > 0.001: #0.1%\n",
    "                # fpr 이 thresholds 값 이상이 될 때 그 index 를 찾음\n",
    "                if (i > 0): i -= 1\n",
    "                break\n",
    "\n",
    "    predicted = pred >= thresholds[i]\n",
    "    TP = int(sum(np.logical_and(test_ground_truth==1,  predicted==1)))\n",
    "    TN = int(sum(np.logical_and(test_ground_truth==0,  predicted==0)))\n",
    "    FP = int(sum(np.logical_and(test_ground_truth==0,  predicted==1)))\n",
    "    FN = int(sum(np.logical_and(test_ground_truth==1,  predicted==0)))\n",
    "\n",
    "    Precision = TP/(TP+FP)\n",
    "    Recall = TP/(TP+FN)\n",
    "\n",
    "    print(TP, TN, FP, FN)\n",
    "\n",
    "    print(\"precision: \", Precision)\n",
    "    print(\"recall: \", Recall)\n",
    "    print(\"F-measure:\", (2*Precision*Recall)/(Precision+Recall+1e-7))\n",
    "    print(\"MCC:\", (TP*TN-FP*FN)/(np.sqrt(float((TP+FN)*(TP+FP)*(TN+FP)*(TN+FN)))+1e-7))\n",
    "    print('='*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
